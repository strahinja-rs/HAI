---
type: concept
status: seed
created: 2026-02-02
modified: 2026-02-02
author: human
confidence: medium
sources:
  - "[[SRC-Gemini-2026-Qualitative-Research-Frameworks-HAI]]"
publish: false
tags: [type/concept, domain/cognition, domain/design, evidence/theoretical]
summary: Cognition arises between agents through interaction, not inside either agent alone. Each agent enacts its own cognitive domain, and interaction is where those domains overlap.
---

# Enactivism

## Definition

Enactivism holds that cognition arises through dynamic interaction between an agent and its environment — not inside the agent's head. Each agent enacts its own cognitive domain: the set of distinctions and meanings it can make based on how it acts. A bee enacts a world of flowers and ultraviolet patterns. A human enacts a world of language and social meaning.

In HAI, the claim extends: an AI system also enacts its own cognitive domain — the set of patterns it can distinguish and respond to. The interaction between human and AI is where two enacted cognitive domains meet and overlap.

## The Core Claim

Cognition is not computation happening inside a box. It is something that happens *between* — in the encounter, in the action, in the overlap zone. The knowledge is in the encounter, not the mechanism.

## Key Aspects

- Post-cognitivist: rejects the information-processing model of mind (brain as computer)
- "Participatory sense-making": when two agents interact, meaning is co-constructed — not transmitted from one to the other
- Challenges the standard HAI framing where the human "uses" a tool — in the enactivist view, both sides are participating in meaning-making
- Whether current AI systems truly "enact cognitive domains" or merely simulate pattern-matching is an open philosophical question

## Enhanced / Extended / Replaced Through This Lens

The enactivist framing reframes [[Augmentation-Modes]]:
- **Enhanced:** your enacted domain stays the same, but your capacity within it is amplified
- **Extended:** your enacted domain expands — you can make distinctions you couldn't before
- **Replaced:** the AI enacts a domain you used to enact — your domain shrinks

## Connections

- Related concepts: [[Interaction-Field]] (the field IS the overlap zone of two enacted cognitive domains — enactivism provides the theoretical foundation), [[Stochastic-Epistemology]] (if AI enacts a probabilistic cognitive domain, interacting with it shifts your epistemology), [[Friction-Discernment]] (choosing which cognitive domains to keep enacting yourself)
- Origin: Francisco Varela, Evan Thompson, Eleanor Rosch — *The Embodied Mind* (1991)
- Also: Humberto Maturana (autopoiesis), the broader "4E cognition" movement (embodied, embedded, enacted, extended)
- Adjacent: Michael Levin's cognitive lightcone — the boundary of what an agent can perceive and act on, defining the scope of its "self"
- Tensions with: classical cognitive science, information-processing models, the view of AI as "just a tool"

## Open Questions

- Does a current LLM genuinely enact a cognitive domain, or is this a useful metaphor that overextends?
- If both human and AI enact domains, what determines the quality of their overlap? (This is the Interaction Field question, now with theoretical grounding)
- How does the enacted domain of an AI change as the model improves? Does the overlap zone with the human shift?
